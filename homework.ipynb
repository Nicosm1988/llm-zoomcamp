{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0001d1c2-6b8e-4c43-93eb-8f6b7c7154a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents: 948\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55385079-5c31-4ac6-80db-8dc6b9e06951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b03f8c62274b1e9298c7b4e5e310ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "if not es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.create(index=index_name, **index_settings)\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)\n",
    "\n",
    "print(\"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc4da93-3ecc-46ea-a765-c551e9c20c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 55.260803\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I execute a command on a Kubernetes pod?\"\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": query,\n",
    "            \"fields\": [\"question^4\", \"text\"], # Boost de 4 para el campo 'question'\n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, **search_query)\n",
    "\n",
    "top_score = response['hits']['hits'][0]['_score']\n",
    "print(f\"score: {top_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca609ba-aba1-4a49-918e-5cc635352159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions:\n",
      "- How do I debug a docker container?\n",
      "- How do I debug a docker container?\n",
      "- How do I debug a docker container?\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I copy a file to a Docker container?\"\n",
    "\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 3,  \n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"], \n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\" \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, **search_query)\n",
    "\n",
    "results_q4 = response['hits']['hits']\n",
    "\n",
    "print(\"questions:\")\n",
    "for hit in results_q4:\n",
    "    print(f\"- {hit['_source']['question']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea19d738-4867-4258-b4e2-ac71a93581bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 1324\n"
     ]
    }
   ],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "context = \"\"\n",
    "for hit in results_q4:\n",
    "    doc = hit['_source']\n",
    "    context += f\"{context_template.format(question=doc['question'], text=doc['text'])}\\n\\n\"\n",
    "\n",
    "question_for_llm = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = prompt_template.format(question=question_for_llm, context=context)\n",
    "\n",
    "prompt_length = len(prompt)\n",
    "print(f\"length: {prompt_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e010a4be-4a3d-4eca-b898-ef0ee9fb015a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tok: 298\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"num_tok: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf28eb43-69c3-48ec-b462-6c253e706091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e0d963-a1bc-4431-88a4-2d8da3be051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d31fba-4484-4674-875d-b8cc3275e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ae812a-ce6f-416e-98b7-6dde1d7ee399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ok\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash-latest') \n",
    "\n",
    "print(\"Model Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca978f3-3629-4dd1-bd9d-9cc88d7f33c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response generated by Gemini:\n",
      "First, find the container ID using the command `docker ps`.  Then, execute the command `docker exec -it <container-id> bash` to execute a command in the specific container.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_answer = llm(prompt)\n",
    "\n",
    "print(\"Response generated by Gemini:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e276a32b-5989-4345-b22f-c94d9ae6c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = ollama.chat(\n",
    "        model='tinyllama', \n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688e9fc4-b95a-4b0b-82f3-4fc8dfd0f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            cv = TfidfVectorizer(**vectorizer_params)\n",
    "            X = cv.fit_transform(self.df[f])\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = cv\n",
    "\n",
    "    def search(self, query, n_results=5, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            score = score + b * s\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ca48297-ea04-47ba-8516-3cdb9dc8949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = TextSearch(\n",
    "    text_fields=['section', 'question', 'text']\n",
    ")\n",
    "\n",
    "index.fit(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f172bb0c-23d5-4f16-b24d-0a5b4a7fd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_TEMPLATE = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        doc_str = CONTEXT_TEMPLATE.format(question=doc['question'], text=doc['text'])\n",
    "        context += f\"{doc_str}\\n\\n\"\n",
    "    \n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        question=query,\n",
    "        context=context.strip()\n",
    "    ).strip()\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f4225-bdbc-43c5-805a-bbc0ddf81922",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'how do I run kafka?'\n",
    "\n",
    "search_results = index.search(query=query, n_results=5)\n",
    "\n",
    "prompt = build_prompt(query, search_results)\n",
    "\n",
    "answer = llm(prompt)\n",
    "\n",
    "print(\"Response generated by tinyllama:\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
