{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8661040-ea05-45c8-a9ef-3aad7beb741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'jinaai/jina-embeddings-v2-small-en' loaded successfully.\n",
      "\n",
      "Query: 'I just discovered the course. Can I join now?'\n",
      "Embedding dimensionality: 512\n",
      "Minimum value in embedding: -0.11726373885183883\n",
      "\n",
      "--- Q1 Answer ---\n",
      "The minimum value is -0.1173\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "query_text = 'I just discovered the course. Can I join now?'\n",
    "model_name = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "embedding_model = TextEmbedding(model_name=model_name)\n",
    "print(f\"Model '{model_name}' loaded successfully.\")\n",
    "\n",
    "embeddings_list = list(embedding_model.embed(query_text))\n",
    "query_embedding = embeddings_list[0]\n",
    "\n",
    "dimensionality = query_embedding.shape[0]\n",
    "min_value = query_embedding.min()\n",
    "\n",
    "print(f\"\\nQuery: '{query_text}'\")\n",
    "print(f\"Embedding dimensionality: {dimensionality}\")\n",
    "print(f\"Minimum value in embedding: {min_value}\")\n",
    "\n",
    "print(\"\\n--- Q1 Answer ---\")\n",
    "print(f\"The minimum value is {min_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f55d7-5c3e-4552-8971-d787ab899f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and new document: 0.9008528895674548\n",
      "\n",
      "--- Q2 Answer ---\n",
      "The calculated similarity is 0.9009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_doc_text = 'Can I still join the course after the start date?'\n",
    "\n",
    "new_doc_embedding_list = list(embedding_model.embed(new_doc_text))\n",
    "new_doc_embedding = new_doc_embedding_list[0]\n",
    "\n",
    "cosine_similarity = query_embedding.dot(new_doc_embedding)\n",
    "\n",
    "print(f\"Cosine similarity between query and new document: {cosine_similarity}\")\n",
    "\n",
    "print(\"\\n--- Q2 Answer ---\")\n",
    "print(f\"The calculated similarity is {cosine_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ef983a-147d-4e42-9f6a-5d1ffc8d772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for each document:\n",
      "[0.76296847 0.81823782 0.80853974 0.7133079  0.73044992]\n",
      "\n",
      "Index of the document with the highest similarity: 1\n",
      "\n",
      "--- Q3 Answer ---\n",
      "The index with the highest score is 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.', 'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.', 'section': 'General course-related questions', 'question': 'How can we contribute to the course?', 'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "\n",
    "doc_texts = [d['text'] for d in documents]\n",
    "doc_embeddings = embedding_model.embed(doc_texts)\n",
    "doc_embeddings_array = np.array(list(doc_embeddings))\n",
    "\n",
    "scores = doc_embeddings_array.dot(query_embedding)\n",
    "best_doc_index = np.argmax(scores)\n",
    "\n",
    "print(\"Similarity scores for each document:\")\n",
    "print(scores)\n",
    "print(f\"\\nIndex of the document with the highest similarity: {best_doc_index}\")\n",
    "\n",
    "print(\"\\n--- Q3 Answer ---\")\n",
    "print(f\"The index with the highest score is {best_doc_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2ff9ca-b915-42e6-b237-069d803cacb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New similarity scores for each document (using 'question' + 'text'):\n",
      "[0.85145432 0.84365942 0.8408287  0.7755158  0.80860078]\n",
      "\n",
      "New index of the document with the highest similarity: 0\n",
      "\n",
      "--- Q4 Answer ---\n",
      "The new best index is 0.\n",
      "The result is different from Q3.\n",
      "Reason: Concatenating the 'question' with the 'text' provides more specific semantic context to the embedding model, which can lead to a better alignment with the query and thus a different ranking.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "full_texts = [f\"{d['question']} {d['text']}\" for d in documents]\n",
    "full_text_embeddings = embedding_model.embed(full_texts)\n",
    "full_text_embeddings_array = np.array(list(full_text_embeddings))\n",
    "\n",
    "new_scores = full_text_embeddings_array.dot(query_embedding)\n",
    "new_best_doc_index = np.argmax(new_scores)\n",
    "\n",
    "print(\"New similarity scores for each document (using 'question' + 'text'):\")\n",
    "print(new_scores)\n",
    "print(f\"\\nNew index of the document with the highest similarity: {new_best_doc_index}\")\n",
    "\n",
    "print(\"\\n--- Q4 Answer ---\")\n",
    "print(f\"The new best index is {new_best_doc_index}.\")\n",
    "\n",
    "if new_best_doc_index == best_doc_index:\n",
    "    print(\"The result is the same as in Q3.\")\n",
    "else:\n",
    "    print(\"The result is different from Q3.\")\n",
    "    print(\"Reason: Concatenating the 'question' with the 'text' provides more specific semantic context to the embedding model, which can lead to a better alignment with the query and thus a different ranking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "460ce7db-46e1-4564-b2c2-bf046ce8ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8803ecacb24e75bd901bd7be7cc34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc447e26d58e4937a49f4443204e477c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bababce9964e40adf67a66f3804582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f756349696d44bfa0a9308c8fb5c25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966a5b48098140e0a3363d63706ae4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e342e9cc9cef466e8a4141059b67423b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the model 'BAAI/bge-small-en' is: 384\n",
      "\n",
      "--- Q5 Answer ---\n",
      "Based on the provided options, the smallest available dimensionality for high-performance models like the one tested is 384.\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "model_name_q5 = \"BAAI/bge-small-en\"\n",
    "embedding_model_q5 = TextEmbedding(model_name=model_name_q5, cache_dir=\"models\")\n",
    "\n",
    "sample_text = \"This is a sample text to check dimensionality.\"\n",
    "sample_embedding = list(embedding_model_q5.embed(sample_text))[0]\n",
    "dimensionality_q5 = sample_embedding.shape[0]\n",
    "\n",
    "print(f\"The dimensionality of the model '{model_name_q5}' is: {dimensionality_q5}\")\n",
    "\n",
    "print(\"\\n--- Q5 Answer ---\")\n",
    "print(\"Based on the provided options, the smallest available dimensionality for high-performance models like the one tested is 384.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338ef09c-0a2a-4698-be5c-6af1d94677e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents for 'machine-learning-zoomcamp': 375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4141c7152f4eb98364c260449442cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1647082a5946dc88a1ad20ea53a5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc84fc4b4b24e09ac723c79b6a07626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d57fe355ae34058bb4b36d9e913af6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db0232e7abe496aaeadf2fd0ecaaf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaedac8b67141afbd03a14058ce2c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taligent\\AppData\\Local\\Temp\\ipykernel_19088\\710950143.py:29: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qd_client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'ml-zoomcamp-faq' created or recreated successfully.\n",
      "Upsert operation completed.\n",
      "\n",
      "Search query: 'I just discovered the course. Can I join now?'\n",
      "The highest score from the search result is: 0.739779\n",
      "\n",
      "--- Q6 Answer ---\n",
      "The highest score is 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taligent\\AppData\\Local\\Temp\\ipykernel_19088\\710950143.py:63: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qd_client.search(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# 1. Download and filter the documents\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name == 'machine-learning-zoomcamp':\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            documents.append(doc)\n",
    "\n",
    "print(f\"Number of documents for 'machine-learning-zoomcamp': {len(documents)}\")\n",
    "\n",
    "# 2. Initialize the new embedding model\n",
    "model_name_q6 = \"BAAI/bge-small-en-v1.5\" # Using the full name for clarity\n",
    "embedding_model_q6 = TextEmbedding(model_name=model_name_q6, cache_dir=\"models\")\n",
    "\n",
    "# 3. Initialize Qdrant client and create a new collection\n",
    "qd_client = QdrantClient(\"http://localhost:6333\")\n",
    "collection_name_q6 = \"ml-zoomcamp-faq\"\n",
    "embedding_dimensionality_q6 = 384\n",
    "\n",
    "qd_client.recreate_collection(\n",
    "    collection_name=collection_name_q6,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=embedding_dimensionality_q6,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(f\"Collection '{collection_name_q6}' created or recreated successfully.\")\n",
    "\n",
    "# 4. Prepare and upsert points with manual embedding\n",
    "\n",
    "texts_to_embed_q6 = [f\"{d['question']} {d['text']}\" for d in documents]\n",
    "embeddings_q6 = embedding_model_q6.embed(texts_to_embed_q6, batch_size=32)\n",
    "\n",
    "points_q6 = []\n",
    "for idx, doc in enumerate(documents):\n",
    "    point = models.PointStruct(\n",
    "        id=idx,\n",
    "        vector=next(embeddings_q6).tolist(), # Using next() on the generator\n",
    "        payload=doc\n",
    "    )\n",
    "    points_q6.append(point)\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=collection_name_q6,\n",
    "    points=points_q6,\n",
    "    wait=True\n",
    ")\n",
    "print(\"Upsert operation completed.\")\n",
    "\n",
    "# 5. Search the collection\n",
    "query_text_q1 = 'I just discovered the course. Can I join now?'\n",
    "query_vector = list(embedding_model_q6.embed(query_text_q1))[0]\n",
    "\n",
    "search_result = qd_client.search(\n",
    "    collection_name=collection_name_q6,\n",
    "    query_vector=query_vector,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "highest_score = search_result[0].score\n",
    "\n",
    "print(f\"\\nSearch query: '{query_text_q1}'\")\n",
    "print(f\"The highest score from the search result is: {highest_score}\")\n",
    "\n",
    "print(\"\\n--- Q6 Answer ---\")\n",
    "print(f\"The highest score is {highest_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114225b-c25b-4afc-a796-3994f98f880d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
